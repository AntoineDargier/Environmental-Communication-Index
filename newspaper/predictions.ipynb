{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import CamembertConfig, CamembertModel, AutoTokenizer, CamembertTokenizer, CamembertForSequenceClassification\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import functools\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "from utils import *\n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = load_newspaper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = df_articles[(df_articles.body != '') & (df_articles.title != '')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set gloabal parameters and tokenizer\n",
    "MAX_LEN = 512\n",
    "batch_size = 16\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base',do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader, body_id, input_ids = dataset_to_dataloader(df_articles, tokenizer, level=\"body\", details=True, labels=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['roberta.pooler.dense.weight', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.bias', 'lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'roberta.pooler.dense.bias']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretained model\n",
    "model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=11).to(device)\n",
    "model.load_state_dict(torch.load(\"../models/camembert_11.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1012/1012 [12:04<00:00,  1.40it/s]\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "with torch.no_grad():\n",
    "    predic = np.ones((len(body_text), 11))\n",
    "    for batch in tqdm(test_dataloader):\n",
    "        t_data = batch[0].to(device)\n",
    "        t_mask = batch[1].to(device)\n",
    "        y = model(t_data,attention_mask=t_mask).logits\n",
    "        result = y.cpu().detach().numpy()\n",
    "        predic[i*batch_size:i*batch_size+len(result)] = result\n",
    "        i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8183/8183 [00:00<00:00, 97920.70it/s]\n"
     ]
    }
   ],
   "source": [
    "from scipy.special import softmax\n",
    "\n",
    "prob = softmax(predic, axis=1)\n",
    "\n",
    "concat_proba_body = []\n",
    "c = 0\n",
    "for i in tqdm(range(max(body_id)+1)):\n",
    "    proba = 0\n",
    "    n = 0\n",
    "    while c < len(body_id) and body_id[c] <= i:\n",
    "        ni = len(input_ids[c])\n",
    "        proba += ni * prob[c]\n",
    "        n += ni\n",
    "        c += 1\n",
    "    if n > 0:\n",
    "        concat_proba_body.append(proba / n)\n",
    "    else:\n",
    "        concat_proba_body.append(np.array([0]*11))\n",
    "\n",
    "prob = np.array(concat_proba_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles[\"planete\"] = prob[:, 0]\n",
    "df_articles[\"sport\"] = prob[:, 1]\n",
    "df_articles[\"economie\"] = prob[:, 2]\n",
    "df_articles[\"arts-stars\"] = prob[:, 3]\n",
    "df_articles[\"high-tech\"] = prob[:, 4]\n",
    "df_articles[\"politique\"] = prob[:, 5]\n",
    "df_articles[\"monde\"] = prob[:, 6]\n",
    "df_articles[\"societe\"] = prob[:, 7]\n",
    "df_articles[\"faits_divers\"] = prob[:, 8]\n",
    "df_articles[\"sante\"] = prob[:, 9]\n",
    "df_articles[\"justice\"] = prob[:, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles.to_parquet(\"../data/predictions_proba.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bbc3c3d932324566a9bf4b4a52ddf64063695fc3adbf25b3fda92572428493bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
