{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import CamembertTokenizer, CamembertForSequenceClassification\n",
    "from utils import *\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_articles = load_newspaper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = extract_train_test_dataset(df_articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set gloabal parameters and tokenizer\n",
    "MAX_LEN = 64\n",
    "batch_size = 32\n",
    "tokenizer = CamembertTokenizer.from_pretrained('camembert-base',do_lower_case=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader = dataset_to_dataloader(test_dataset, tokenizer, level='title')\n",
    "train_dataloader = dataset_to_dataloader(train_dataset, tokenizer, level='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at camembert-base were not used when initializing CamembertForSequenceClassification: ['lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.bias', 'roberta.pooler.dense.bias', 'lm_head.dense.weight', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CamembertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.out_proj.bias', 'classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load pretained model\n",
    "model = CamembertForSequenceClassification.from_pretrained(\"camembert-base\", num_labels=7).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract parameters to optimize\n",
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "opt = torch.optim.Adam(optimizer_grouped_parameters, lr=2e-5, eps=10e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| epoch   0 |    50/ 1469 steps | loss 1.81394\n",
      "| epoch   0 |   100/ 1469 steps | loss 1.25588\n",
      "| epoch   0 |   150/ 1469 steps | loss 0.89543\n",
      "| epoch   0 |   200/ 1469 steps | loss 0.78953\n",
      "| epoch   0 |   250/ 1469 steps | loss 0.67403\n",
      "| epoch   0 |   300/ 1469 steps | loss 0.62081\n",
      "| epoch   0 |   350/ 1469 steps | loss 0.58372\n",
      "| epoch   0 |   400/ 1469 steps | loss 0.56182\n",
      "| epoch   0 |   450/ 1469 steps | loss 0.47667\n",
      "| epoch   0 |   500/ 1469 steps | loss 0.50559\n",
      "| epoch   0 |   550/ 1469 steps | loss 0.49567\n",
      "| epoch   0 |   600/ 1469 steps | loss 0.44547\n",
      "| epoch   0 |   650/ 1469 steps | loss 0.45166\n",
      "| epoch   0 |   700/ 1469 steps | loss 0.46312\n",
      "| epoch   0 |   750/ 1469 steps | loss 0.49224\n",
      "| epoch   0 |   800/ 1469 steps | loss 0.45498\n",
      "| epoch   0 |   850/ 1469 steps | loss 0.46739\n",
      "| epoch   0 |   900/ 1469 steps | loss 0.42009\n",
      "| epoch   0 |   950/ 1469 steps | loss 0.47173\n",
      "| epoch   0 |  1000/ 1469 steps | loss 0.44227\n",
      "| epoch   0 |  1050/ 1469 steps | loss 0.45995\n",
      "| epoch   0 |  1100/ 1469 steps | loss 0.43144\n",
      "| epoch   0 |  1150/ 1469 steps | loss 0.43176\n",
      "| epoch   0 |  1200/ 1469 steps | loss 0.41668\n",
      "| epoch   0 |  1250/ 1469 steps | loss 0.43236\n",
      "| epoch   0 |  1300/ 1469 steps | loss 0.40167\n",
      "| epoch   0 |  1350/ 1469 steps | loss 0.40738\n",
      "| epoch   0 |  1400/ 1469 steps | loss 0.37155\n",
      "| epoch   0 |  1450/ 1469 steps | loss 0.40722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [02:52<00:00,  3.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy : 0.671\n",
      "| epoch   1 |    50/ 1469 steps | loss 0.33204\n",
      "| epoch   1 |   100/ 1469 steps | loss 0.24871\n",
      "| epoch   1 |   150/ 1469 steps | loss 0.26962\n",
      "| epoch   1 |   200/ 1469 steps | loss 0.29491\n",
      "| epoch   1 |   250/ 1469 steps | loss 0.25126\n",
      "| epoch   1 |   300/ 1469 steps | loss 0.28984\n",
      "| epoch   1 |   350/ 1469 steps | loss 0.29596\n",
      "| epoch   1 |   400/ 1469 steps | loss 0.27086\n",
      "| epoch   1 |   450/ 1469 steps | loss 0.27196\n",
      "| epoch   1 |   500/ 1469 steps | loss 0.27721\n",
      "| epoch   1 |   550/ 1469 steps | loss 0.26761\n",
      "| epoch   1 |   600/ 1469 steps | loss 0.25930\n",
      "| epoch   1 |   650/ 1469 steps | loss 0.26737\n",
      "| epoch   1 |   700/ 1469 steps | loss 0.29556\n",
      "| epoch   1 |   750/ 1469 steps | loss 0.29903\n",
      "| epoch   1 |   800/ 1469 steps | loss 0.27771\n",
      "| epoch   1 |   850/ 1469 steps | loss 0.29790\n",
      "| epoch   1 |   900/ 1469 steps | loss 0.27438\n",
      "| epoch   1 |   950/ 1469 steps | loss 0.25406\n",
      "| epoch   1 |  1000/ 1469 steps | loss 0.22844\n",
      "| epoch   1 |  1050/ 1469 steps | loss 0.25966\n",
      "| epoch   1 |  1100/ 1469 steps | loss 0.27998\n",
      "| epoch   1 |  1150/ 1469 steps | loss 0.27263\n",
      "| epoch   1 |  1200/ 1469 steps | loss 0.25561\n",
      "| epoch   1 |  1250/ 1469 steps | loss 0.28083\n",
      "| epoch   1 |  1300/ 1469 steps | loss 0.26581\n",
      "| epoch   1 |  1350/ 1469 steps | loss 0.27109\n",
      "| epoch   1 |  1400/ 1469 steps | loss 0.27044\n",
      "| epoch   1 |  1450/ 1469 steps | loss 0.25956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [02:49<00:00,  3.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy : 0.704\n"
     ]
    }
   ],
   "source": [
    "model = train(model, train_dataloader, test_dataloader, opt, epochs=2, level='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/camembert_title.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bbc3c3d932324566a9bf4b4a52ddf64063695fc3adbf25b3fda92572428493bb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
